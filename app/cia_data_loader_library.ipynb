{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b0ef292-8166-4467-ab79-60661e0e5d5d",
   "metadata": {},
   "source": [
    "# Funciones desarrolladas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1d8951-5c26-4106-8132-56a676e79bee",
   "metadata": {},
   "source": [
    "1.2. ğŸ› ï¸ InstalaciÃ³n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8e3887-b9c9-451c-b04d-2fdbab4427c8",
   "metadata": {},
   "source": [
    "### ğŸ”§Carga de librerias en el entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15710195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de CSV\n",
    "import pandas as pd\n",
    "\n",
    "# Funciones de carga de ficheros\n",
    "import os\n",
    "# Para generar el grÃ¡fico de dependecias\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "# Calculo de localizaciones\n",
    "import math\n",
    "import geocoder\n",
    "\n",
    "import inspect\n",
    "\n",
    "\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "from sqlalchemy import create_engine, inspect\n",
    "import pandas as pd\n",
    "\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sqlalchemy.exc import SQLAlchemyError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51439849-9cc0-483a-bb66-b340b8c70f4b",
   "metadata": {},
   "source": [
    "## ğŸ’» Funciones sobre el sistema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dc8300-980b-4581-9676-a5f1475c27a2",
   "metadata": {},
   "source": [
    "### clean_file\n",
    "\n",
    "ğŸ” Â¿QuÃ© hace?\n",
    "\n",
    "Esta funciÃ³n recorre todos los archivos dentro de un **directorio (y sus subdirectorios)** y limpia los saltos de lÃ­nea Windows (**\\r\\n**), reemplazÃ¡ndolos por saltos de lÃ­nea estÃ¡ndar de Unix (\\n), en archivos que tengan extensiones especÃ­ficas (*por defecto, .txt*).\n",
    "\n",
    "ğŸ§± Â¿QuÃ© hace paso a paso?\n",
    "\n",
    "Recorrer el directorio y subdirectorios. \n",
    "\n",
    "La funciÃ³n filtra los archivos para solo procesar aquellos que tienen extensiones que coinciden con las proporcionadas en el parÃ¡metro extensions.\n",
    "\n",
    "Abrir y leer el contenido del archivo:\n",
    "\n",
    "Limpiar el contenido del archivo reemplaza los saltos de lÃ­nea \\r\\n (utilizados en sistemas Windows) por \\n (salto de lÃ­nea estÃ¡ndar en sistemas Unix/Linux).\n",
    "\n",
    "\n",
    "DespuÃ©s de limpiar el contenido y se sobrescribe con el contenido limpio.\n",
    "\n",
    "Manejo de errores:\n",
    "\n",
    "Si ocurre un error durante la lectura o escritura del archivo, se captura con un bloque try-except y se imprime un mensaje de error, pero el proceso continÃºa con el siguiente archivo.\n",
    "\n",
    "Si ocurre un error al recorrer los directorios o abrir el archivo principal, se devuelve un mensaje de error indicando la excepciÃ³n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8892690f-f89f-4458-81af-2664ee6e1721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_file(directory, extensions=['.txt']):\n",
    "    try : \n",
    "      for root, dirs, files in os.walk(directory):  # Recorrer directorios y subdirectorios\n",
    "        for file_name in files:\n",
    "            # print('extension:',extensions)\n",
    "            if any(file_name.endswith(extension) for extension in extensions):  # Filtra por extensiones\n",
    "                file_path = os.path.join(root, file_name)  # Obtiene la ruta completa\n",
    "                # print(f'Procesando archivo: {file_path}')\n",
    "                \n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                        content = f.read()\n",
    "\n",
    "                    content_cleaned = content.replace('\\r\\n', '\\n')\n",
    "\n",
    "                    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "                        f.write(content_cleaned)\n",
    "\n",
    "                    # print(f'âœ” Procesado: {file_name}')\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f'âŒ Error al procesar {file_name}: {e}. Se omitirÃ¡.')\n",
    "    except Exception:\n",
    "        return f'error {Exception}'\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c7e02bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a221ab-2534-46ca-bdda-2f4d84c273c5",
   "metadata": {},
   "source": [
    "## ImportaciÃ³n de Librerias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4e049a-7438-4cf0-b20b-afdd03f3f01c",
   "metadata": {},
   "source": [
    "## ğŸ“Š De tratamiento de las entidades del dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6d0c42-15a7-4689-97f7-9975803735bb",
   "metadata": {},
   "source": [
    "### lowercase_if_letters_only\n",
    "\n",
    "ğŸ” Â¿QuÃ© hace?\n",
    "\n",
    "FunciÃ³n para convertir a minÃºsculas solo las columnas con letras\n",
    "\n",
    "\n",
    "ğŸ§± Â¿QuÃ© hace paso a paso?\n",
    "\n",
    "    1. Recorre todas las columnas del DataFrame.\n",
    "    2. Para cada columna:\n",
    "       - Convierte cada valor a cadena.\n",
    "       - Verifica si contiene solo letras. (para evitar tocar las columnas que tienen numeros\n",
    "    3. Si todos los valores de la columna son letras:\n",
    "       - Convierte la columna completa a minÃºsculas usando.\n",
    "    4. Devuelve el DataFrame modificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c6aee10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase_if_letters_only(df_temp):\n",
    "    try: \t\n",
    "        for col in df_temp.columns:\n",
    "            if df_temp[col].apply(lambda x: str(x).isalpha()).all():\n",
    "                df_temp[col] = df_temp[col].str.lower()\n",
    "        return df_temp\n",
    "    except Exception:\n",
    "        return f'error {Exception}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ab854f-9c5c-4578-b38a-2ecf7bf67178",
   "metadata": {},
   "source": [
    "### is_words(column)\n",
    "\n",
    " ğŸ” Â¿QuÃ© hace?\n",
    "\n",
    " Verifica si todos los valores de una columna son solo letras (sin nÃºmeros ni caracteres especiales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "911aeb7e-bd48-4bf0-b386-f012061e2ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_words(column):\n",
    "   return column.apply(lambda x: bool(re.match(r'^[A-Za-z]+$', str(x)))).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c642ffae-0c33-48a8-8122-68dd5dc44abf",
   "metadata": {},
   "source": [
    "### lower_column\n",
    "\n",
    "ğŸ” Â¿QuÃ© hace?\n",
    "\n",
    "Verifica si todos los valores en una serie contienen solo letras (ignorando strings vacÃ­os).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "001d033d-838c-407c-81b6-52dea29f3ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_column(df_temp, columns_str):\n",
    "    for column in columns_str:\n",
    "        if column in df_temp.columns:\n",
    "            # Convertir la columna a tipo string, manejando nulos\n",
    "            df_temp[column] = df_temp[column].fillna('').astype(str)\n",
    "            \n",
    "            # Verificar si todos los valores son letras\n",
    "            if is_words(df_temp[column]):\n",
    "                # Si todos los valores son letras, convertir a minÃºsculas\n",
    "                df_temp[column] = df_temp[column].str.lower()\n",
    "\n",
    "    return df_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1fb84c-94c9-4159-a94a-84fb102848a5",
   "metadata": {},
   "source": [
    "### load_files_in_dataframes\n",
    "\n",
    "ğŸ” Â¿QuÃ© hace?\n",
    "\n",
    "La funciÃ³n load_files_in_dataframes carga todos los archivos .csv o .txt de un directorio (y sus subdirectorios) en DataFrames de pandas, realizando varias transformaciones especÃ­ficas.\n",
    "\n",
    "ğŸ§± Paso a paso\n",
    "* Inicializa listas y diccionarios:\n",
    "\n",
    "lista_id: almacena nombres de columnas que terminan en _id o empiezan por id.\n",
    "\n",
    "dataframes: contiene los DataFrames con claves basadas en el nombre del archivo.\n",
    "\n",
    "ğŸ”¹  Recorre los archivos del directorio:\n",
    "\n",
    "* Ignora subdirectorios (aunque los recorre recursivamente).\n",
    "\n",
    "ğŸ”¹ Filtra archivos por extensiÃ³n (.csv o .txt).\n",
    "\n",
    "* Procesa cada archivo vÃ¡lido:\n",
    "\n",
    "* Lee el archivo como DataFrame con pandas.read_csv().\n",
    "\n",
    "* Convierte los nombres de columnas a minÃºsculas.\n",
    "\n",
    "* Renombra columnas usando convert_list.\n",
    "\n",
    "* Realiza slicing o manipulaciÃ³n de columnas definidas en convert_keys.\n",
    "\n",
    "* Si existe la columna objectid, la usa como Ã­ndice.\n",
    "\n",
    "ğŸ”¹ Limpieza de datos:\n",
    "\n",
    "* Detecta columnas que contengan solo letras (excepto las columnas con id) y las convierte a minÃºsculas con lower_column.\n",
    "\n",
    "ğŸ”¹ Guarda el resultado:\n",
    "\n",
    "* Crea un DataFrame con nombre df_nombre_del_archivo.\n",
    "\n",
    "* TambiÃ©n lo guarda en el diccionario dataframes.\n",
    "\n",
    "ğŸ”¹ Manejo de errores:\n",
    "\n",
    "* Ignora archivos vacÃ­os o con errores de anÃ¡lisis (pandas.errors.EmptyDataError o ParserError).\n",
    "\n",
    "* Captura otros errores inesperados sin interrumpir el procesamiento.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3397b662-20af-4b20-a098-ea3db238d48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_files_in_dataframes(file_path, sep=',', extensions=['.txt', '.csv']):\n",
    "    all_ids = set()\n",
    "    dataframes = {}\n",
    "\n",
    "    try:\n",
    "        for full_file_name in os.listdir(file_path):\n",
    "            filepath = os.path.join(file_path, full_file_name)\n",
    "            \n",
    "            # Si es una subcarpeta, recursivamente procesa\n",
    "            if os.path.isdir(filepath):\n",
    "                sub_dataframes, sub_ids = load_files_in_dataframes(filepath, sep=sep, extensions=extensions)\n",
    "                dataframes.update(sub_dataframes)\n",
    "                all_ids.update(sub_ids)\n",
    "                continue\n",
    "\n",
    "            # Procesar solo archivos con extensiÃ³n vÃ¡lida\n",
    "            if any(full_file_name.endswith(ext) for ext in extensions):\n",
    "                file_name = os.path.splitext(full_file_name)[0]  # sin extensiÃ³n\n",
    "                print(f'Procesando archivo: {full_file_name}')\n",
    "                try:\n",
    "                    df = pd.read_csv(filepath, sep=sep, header=0)\n",
    "                    df.columns = df.columns.str.lower()  # Normalizar nombres de columnas\n",
    "                    \n",
    "                    # Detectar columnas ID\n",
    "                    ids_in_file = [col for col in df.columns if col.endswith('_id') or col.startswith('id')]\n",
    "                    all_ids.update(ids_in_file)\n",
    "                    \n",
    "                    if ids_in_file:\n",
    "                        print(f'df_{file_name} contiene IDs: {ids_in_file}')\n",
    "\n",
    "                    df_name = f\"df_{file_name}\"\n",
    "                    globals()[df_name] = df  # no recomendable fuera de notebooks, pero Ãºtil en exploraciÃ³n\n",
    "                    dataframes[file_name] = df\n",
    "\n",
    "                except pd.errors.EmptyDataError:\n",
    "                    print(f\"Advertencia: El archivo {full_file_name} estÃ¡ vacÃ­o. Se omitirÃ¡.\")\n",
    "                except pd.errors.ParserError as e:\n",
    "                    print(f\"Error al analizar el archivo {full_file_name}: {e}. Se omitirÃ¡.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error inesperado al procesar {full_file_name}: {e}. Se omitirÃ¡.\")\n",
    "\n",
    "        return dataframes, list(all_ids)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: El directorio '{file_path}' no existe.\")\n",
    "        return {}, []\n",
    "    except Exception as e:\n",
    "        print(f\"Error inesperado: {e}\")\n",
    "        return {}, []\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492c1449-a46e-4a31-ad12-989cfff86934",
   "metadata": {},
   "source": [
    "### detect_keys\n",
    "\n",
    "ğŸ” Â¿Que hace?\n",
    "\n",
    "ğŸ”¹ Detectar automÃ¡ticamente claves primarias y claves forÃ¡neas en un DataFrame de pandas, basÃ¡ndose en los nombres de columnas y si sus valores son Ãºnicos o repetidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8201ca7-3aa0-4326-90cc-fd8df93a4041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_keys(df):\n",
    "    # Detectar claves primarias (columnas Ãºnicas que terminan con '_id' o comienzan con 'id')\n",
    "    primary_keys = [col for col in df.columns if df[col].is_unique and (col.endswith('_id') or col.startswith('id'))]\n",
    "    \n",
    "    # Detectar claves forÃ¡neas (columnas no Ãºnicas que terminan con '_id')\n",
    "    foreign_keys = [col for col in df.columns if not df[col].is_unique and col.endswith('_id')]\n",
    "    \n",
    "    return primary_keys, foreign_keys "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca898dae-a994-41df-99c0-a2b2ea4e67d1",
   "metadata": {},
   "source": [
    "### build_dependency_graph\n",
    "\n",
    "ğŸ” Â¿Que hace?\n",
    "\n",
    "La funciÃ³n construye un grafo de dependencias, entre tablas a partir de un conjunto de DataFrames de pandas. Este grafo permite conocer en quÃ© orden se deben insertar las tablas en una base de datos relacional (como PostgreSQL), respetando sus dependencias por claves forÃ¡neas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e28c64a-eb48-4422-9791-15c83efcb2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dependency_graph(dataframes):\n",
    "    graph = defaultdict(list)  # Diccionario para almacenar las dependencias\n",
    "    all_tables = set(dataframes.keys())  # Conjunto de todos los nombres de tablas\n",
    "\n",
    "    for table_name, df in dataframes.items():\n",
    "        # Detecta claves primarias y forÃ¡neas en el DataFrame\n",
    "        _, foreign_keys = detect_keys(df)\n",
    "        \n",
    "        for fk in foreign_keys:\n",
    "            # Elimina el sufijo '_id' para obtener el nombre de la tabla referenciada\n",
    "            ref_table = fk[:-3] if fk.endswith('_id') else fk\n",
    "            \n",
    "            # Si la tabla referenciada existe en el conjunto de tablas, agrega la dependencia\n",
    "            if ref_table in dataframes:\n",
    "                graph[ref_table].append(table_name)\n",
    "        \n",
    "        # Asegura que la tabla actual estÃ© en el grafo, incluso si no tiene dependencias\n",
    "        if table_name not in graph:\n",
    "            graph[table_name] = []\n",
    "\n",
    "    return graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994d36df-c113-4ff5-b608-53e1996558db",
   "metadata": {},
   "source": [
    "### topological_sort_all_nodes\n",
    "\n",
    "ğŸ” Â¿Que hace?\n",
    "\n",
    "Su objetivo es determinar un orden de inserciÃ³n de tablas en una base de datos respetando las dependencias entre ellas (por ejemplo, claves forÃ¡neas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7b4340f-51d7-4d58-9272-fb8b017b9636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topological_sort_all_nodes(graph):\n",
    "    indegree = {node: 0 for node in graph}\n",
    "    for node in graph:\n",
    "        for neighbor in graph[node]:\n",
    "            indegree[neighbor] += 1\n",
    "\n",
    "    queue = deque([node for node in graph if indegree[node] == 0])\n",
    "    order = []\n",
    "\n",
    "    while queue:\n",
    "        node = queue.popleft()\n",
    "        order.append(node)\n",
    "        for neighbor in graph[node]:\n",
    "            indegree[neighbor] -= 1\n",
    "            if indegree[neighbor] == 0:\n",
    "                queue.append(neighbor)\n",
    "\n",
    "    if len(order) != len(graph):\n",
    "        print(\"âš ï¸ Cuidado: se detectÃ³ una posible dependencia cÃ­clica.\")\n",
    "    return order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f59fc7fd-327a-40fa-b247-8f40e0f8ba5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topological_sort(graph):\n",
    "    visited = set()\n",
    "    order = []\n",
    "\n",
    "    def dfs(node):\n",
    "        if node in visited:\n",
    "            return\n",
    "        visited.add(node)\n",
    "        for neighbor in graph.get(node, []):\n",
    "            dfs(neighbor)\n",
    "        order.append(node)\n",
    "\n",
    "    for node in graph:\n",
    "        dfs(node)\n",
    "\n",
    "    return list(reversed(order))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b486816e-7daf-459d-80af-e9c4af7869c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_columns(df):\n",
    "    \"\"\"\n",
    "    Retorna un diccionario con el nombre de la variable del DataFrame y sus columnas con valores Ãºnicos.\n",
    "    \"\"\"\n",
    "    # Inspeccionar el stack para encontrar el nombre de la variable pasada como argumento\n",
    "    callers_local_vars = inspect.currentframe().f_back.f_locals.items()\n",
    "    df_name = next((name for name, val in callers_local_vars if val is df), \"dataframe\")\n",
    "\n",
    "    unique_cols = [col for col in df.columns if df[col].is_unique]\n",
    "    return df_name,unique_cols\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898d4a91-09ad-43f7-a98d-780a70116062",
   "metadata": {},
   "source": [
    "### insert_dataframes_to_postgres\n",
    "\n",
    "\n",
    "ğŸ” Â¿QuÃ© hace?\n",
    "Inserta DataFrames en una base de datos PostgreSQL en el orden especificado, creando las tablas si no existen.\n",
    "\n",
    "    ParÃ¡metros:\n",
    "        - dataframes: dict de DataFrames a insertar.\n",
    "        - insertion_order: orden de inserciÃ³n (respetando claves forÃ¡neas).\n",
    "        - postgres_user: usuario de la base de datos.\n",
    "        - postgres_password: contraseÃ±a.\n",
    "        - postgres_db: nombre de la base de datos.\n",
    "        - host: direcciÃ³n del servidor PostgreSQL.\n",
    "        - port: puerto del servidor.\n",
    "        - if_exists: comportamiento si la tabla existe ('fail', 'replace', 'append').\n",
    "        - unique_columns: Un diccionario que mapea el nombre de la tabla con las columnas que se deben considerar Ãºnicas para evitar duplicados. Esto es Ãºtil cuando queremos evitar que se inserten registros con valores duplicados en esas columnas.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ğŸ§± Paso a paso\n",
    "\n",
    "ConexiÃ³n a la base de datos:\n",
    "\n",
    "La funciÃ³n construye una URL de conexiÃ³n a la base de datos usando las credenciales proporcionadas y establece una conexiÃ³n utilizando SQLAlchemy (create_engine).\n",
    "\n",
    "TambiÃ©n se usa el inspector de SQLAlchemy para obtener informaciÃ³n sobre las tablas existentes en la base de datos.\n",
    "\n",
    "Recorrer las tablas en el orden de inserciÃ³n:\n",
    "\n",
    "La funciÃ³n recorre la lista insertion_order para insertar las tablas en el orden especificado.\n",
    "\n",
    "VerificaciÃ³n de la existencia de tablas:\n",
    "\n",
    "Si la tabla ya existe en la base de datos, la funciÃ³n imprime un mensaje indicando que la tabla existe.\n",
    "\n",
    "Si la tabla no existe, se imprimirÃ¡ un mensaje indicando que la tabla se crearÃ¡ automÃ¡ticamente.\n",
    "\n",
    "EliminaciÃ³n de duplicados (si se especifica unique_columns):\n",
    "\n",
    "Si se pasa el parÃ¡metro unique_columns, la funciÃ³n elimina las filas duplicadas de cada DataFrame basÃ¡ndose en las columnas definidas como \"Ãºnicas\" en unique_columns.\n",
    "\n",
    "Este paso es importante porque solo se insertarÃ¡n registros nuevos, evitando duplicados en la base de datos.\n",
    "\n",
    "InserciÃ³n de los registros:\n",
    "\n",
    "La funciÃ³n recorre cada fila del DataFrame y genera una consulta INSERT INTO utilizando la clÃ¡usula ON CONFLICT DO NOTHING.\n",
    "\n",
    "Esto asegura que si ya existe un registro con las mismas columnas Ãºnicas (unique_cols), el registro no se inserte nuevamente (evita duplicados).\n",
    "\n",
    "La consulta ON CONFLICT ({', '.join(unique_cols)}) DO NOTHING indica que, si ocurre un conflicto de clave (es decir, ya existe un registro con los mismos valores en las columnas indicadas en unique_cols), no se realiza ninguna acciÃ³n (se ignora esa inserciÃ³n).\n",
    "\n",
    "Manejo de errores:\n",
    "\n",
    "Si ocurre un error durante la inserciÃ³n de algÃºn registro (por ejemplo, un error SQL), la funciÃ³n captura la excepciÃ³n y muestra el mensaje de error correspondiente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c660c0-552c-43aa-a798-ca4b1d353c10",
   "metadata": {},
   "source": [
    "### insert_dataframes_to_postgres\n",
    "\n",
    "ğŸ” Â¿QuÃ© hace?\n",
    "\n",
    " Tiene como objetivo insertar datos de DataFrames de pandas en una base de datos PostgreSQL, evitando que se inserten registros duplicados basados en columnas Ãºnicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "369ad419-9c42-43b1-abca-ae242bbab9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_dataframes_to_postgres(dataframes, insertion_order, postgres_user, postgres_password, postgres_db, host='localhost', port=5432, if_exists='replace', unique_columns=None):\n",
    "    db_url = f\"postgresql+psycopg2://{postgres_user}:{postgres_password}@{host}:{port}/{postgres_db}\"\n",
    "    print(\"db_url\", db_url)\n",
    "    engine = create_engine(db_url)\n",
    "    \n",
    "    for table in insertion_order:\n",
    "        df = dataframes.get(table)\n",
    "        if df is None:\n",
    "            print(f\"âš ï¸  No se encontrÃ³ DataFrame para la tabla: {table}\")\n",
    "            continue\n",
    "        print(f\"ğŸ”„ Insertando en tabla: {table}\")\n",
    "        \n",
    "        try:\n",
    "            if unique_columns and table in unique_columns:\n",
    "                unique_cols = unique_columns[table]\n",
    "                df = df.drop_duplicates(subset=unique_cols, keep='first')\n",
    "                print(f\"ğŸ” Se eliminaron duplicados basados en las columnas: {unique_cols}\")\n",
    "            \n",
    "            # Usar to_sql para insertar el DataFrame\n",
    "            df.to_sql(table, engine, index=False, if_exists=if_exists)\n",
    "            print(f\"âœ… Datos insertados correctamente en la tabla '{table}'\")\n",
    "        except SQLAlchemyError as e:\n",
    "            print(f\"âŒ Error al insertar '{table}': {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error inesperado al insertar '{table}': {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c594a3-6e0c-4a4d-aafa-2229ae572279",
   "metadata": {},
   "source": [
    "## Dibujar graficos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fd4e55-5ad1-45a2-b9fe-743f3a6dd509",
   "metadata": {},
   "source": [
    "### draw_graf\n",
    "\n",
    "ğŸ” Â¿QuÃ© hace?\n",
    "\n",
    "Es una funciÃ³n para visualizar un grafo utilizando NetworkX para la estructura del grafo y Matplotlib para la visualizaciÃ³n. \n",
    "\n",
    "ğŸ§± ExplicaciÃ³n paso a paso\n",
    "\n",
    "Los nodos estÃ¡n posicionados de manera automÃ¡tica utilizando el algoritmo de disposiciÃ³n de primavera.\n",
    "\n",
    "Los nodos tienen un tamaÃ±o y color definidos.\n",
    "\n",
    "Las etiquetas de los nodos muestran un atributo personalizado ('columnas_comunes').\n",
    "\n",
    "Las aristas son flechas (porque el grafo es dirigido).\n",
    "\n",
    "El grafo tiene un tÃ­tulo que es pasado como parÃ¡metro.\n",
    "\n",
    "Es ideal para representar estructuras de datos, redes de relaciones o dependencias entre elementos (como en anÃ¡lisis de grafos de dependencias o redes de informaciÃ³n)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd48a0f7-dc69-4716-a457-d9c0d4eb43c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graf(grafo, titulo, color):\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    pos = nx.spring_layout(grafo, k=2)\n",
    "    nx.draw(grafo, pos, with_labels=True, node_size=5000, node_color=color, font_size=10, font_weight='bold', arrows=True)\n",
    "    labels = nx.get_node_attributes(grafo, 'columnas_comunes')\n",
    "    nx.draw_networkx_labels(grafo, pos, labels=labels, font_size=8, font_color='black')\n",
    "    plt.title(titulo)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ef7d23-acc5-4d63-8426-588dcf48d834",
   "metadata": {},
   "source": [
    "### dependency_dataframes\n",
    "\n",
    "ğŸ” Â¿QuÃ© hace?\n",
    "\n",
    "Analiza los DataFrames, crea grafos de dependencias y los visualiza.\n",
    "\n",
    "    Args:\n",
    "    \n",
    " ğŸ”¹ globals_dict: Diccionario con variables globales (como globals()).\n",
    " \n",
    " ğŸ”¹ split_key: Subcadena para separar DataFrames en dos grupos.\n",
    "\n",
    "ğŸ§± ExplicaciÃ³n paso a paso\n",
    "\n",
    "ğŸ”¹ Clasifica las relaciones segÃºn si uno de los DataFrames contiene un prefijo como \"df_M4\".\n",
    "\n",
    "ğŸ”¹ Dibuja un grafo visual para mostrar cÃ³mo estÃ¡n conectados.\n",
    "\n",
    "ğŸ”¹ Devuelve toda esa informaciÃ³n para poder usarla luego.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac972d3e-e7bb-47f6-8e0a-80f3849af0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dependency_dataframes(globals_dict, split_key=\"df_M4\"):\n",
    "    \n",
    "\n",
    "    relaciones = {}\n",
    "    relaciones_M4 = {}\n",
    "    relaciones_NO_M4 = {}\n",
    "\n",
    "    G = nx.DiGraph()\n",
    "    G_NO_M4 = nx.DiGraph()\n",
    "    G_M4 = nx.DiGraph()\n",
    "\n",
    "    df_names = [name for name in globals_dict if name.startswith('df_') and isinstance(globals_dict.get(name), pd.DataFrame)]\n",
    "\n",
    "    if not df_names:\n",
    "        return {}, {}, {}, G, G_M4, G_NO_M4\n",
    "\n",
    "    for dfx_name in df_names:\n",
    "        try:\n",
    "            df1 = globals_dict[dfx_name]\n",
    "            columnas_df1 = list(df1.columns)\n",
    "\n",
    "            for df2_name in df_names:\n",
    "                if df2_name != dfx_name:\n",
    "                    df2 = globals_dict[df2_name]\n",
    "                    columnas_df2 = list(df2.columns)\n",
    "                    columnas_comunes = list(set(columnas_df1) & set(columnas_df2))\n",
    "\n",
    "                    if columnas_comunes:\n",
    "                        if df2_name.startswith(split_key) or dfx_name.startswith(split_key):\n",
    "                            relaciones_M4[f\"{dfx_name} - {df2_name}\"] = columnas_comunes\n",
    "                            G_M4.add_edge(dfx_name, df2_name)\n",
    "                        else:\n",
    "                            relaciones_NO_M4[f\"{dfx_name} - {df2_name}\"] = columnas_comunes\n",
    "                            G_NO_M4.add_edge(dfx_name, df2_name)\n",
    "\n",
    "                        G.add_edge(dfx_name, df2_name)\n",
    "                        relaciones[f\"{dfx_name} - {df2_name}\"] = columnas_comunes\n",
    "        except KeyError as e:\n",
    "            print(f\"Error al acceder al DataFrame '{e}': Verifica que el DataFrame estÃ© definido.\")\n",
    "            continue\n",
    "\n",
    "    # Dibujar grafos\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    pos = nx.spring_layout(G, k=0.8)\n",
    "\n",
    "    nx.draw(G_M4, pos, with_labels=True, node_size=4000, node_color='lightblue',\n",
    "            font_size=10, font_weight='bold', edge_color='blue', arrows=True)\n",
    "    nx.draw(G_NO_M4, pos, with_labels=True, node_size=4000, node_color='green',\n",
    "            font_size=10, font_weight='bold', edge_color='lightgreen', arrows=True)\n",
    "\n",
    "    plt.title(\"Grafo de Dependencias entre DataFrames\")\n",
    "    plt.show()\n",
    "\n",
    "    # Devolver resultados\n",
    "    return relaciones, relaciones_M4, relaciones_NO_M4, G, G_M4, G_NO_M4\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b71a261-0d78-4efb-afa3-de8cfda62256",
   "metadata": {},
   "source": [
    "### tree_dataframes\n",
    "\n",
    "ğŸ” Â¿QuÃ© hace?\n",
    "\n",
    "Analiza los DataFrames, crea un grÃ¡fico de arborescencia de dependencias y lo visualiza.\n",
    "\n",
    "Args:\n",
    "\n",
    "ğŸ”¹globals_dict: Diccionario con variables globales (como globals()).\n",
    "        \n",
    "ğŸ”¹split_key: Subcadena para separar DataFrames en dos grupos.\n",
    "\n",
    "ğŸ§± Â¿QuÃ© hace paso a paso?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3ca7f5-968f-482d-b107-0c17b3d2e941",
   "metadata": {},
   "source": [
    "## Funciones GPS\n",
    "\n",
    "Aqui agrupamos las funciones de apoyo para temas de localizaciÃ³n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "801f3881-6280-4e87-9df4-ea74b54a7e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tree_dataframes(globals_dict, split_key=\"df_M4\"):\n",
    "    relaciones = {}\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Detectar los DataFrames\n",
    "    df_names = [\n",
    "        name for name in globals_dict\n",
    "        if name.startswith('df_') and isinstance(globals_dict[name], pd.DataFrame)\n",
    "    ]\n",
    "\n",
    "    if not df_names:\n",
    "        print(\"No se encontraron DataFrames.\")\n",
    "        return\n",
    "\n",
    "    # Buscar relaciones reales basadas en columnas comunes\n",
    "    for dfx_name in df_names:\n",
    "        df1 = globals_dict[dfx_name]\n",
    "        columnas_df1 = set(df1.columns)\n",
    "\n",
    "        for df2_name in df_names:\n",
    "            if df2_name != dfx_name:\n",
    "                df2 = globals_dict[df2_name]\n",
    "                columnas_df2 = set(df2.columns)\n",
    "                columnas_comunes = columnas_df1 & columnas_df2\n",
    "\n",
    "                if columnas_comunes:\n",
    "                    G.add_edge(dfx_name, df2_name)\n",
    "                    relaciones[f\"{dfx_name} -> {df2_name}\"] = list(columnas_comunes)\n",
    "\n",
    "    # Eliminar ciclos detectados para evitar dependencias circulares\n",
    "    try:\n",
    "        ciclo = list(nx.simple_cycles(G))\n",
    "        if ciclo:\n",
    "            print(f\"Ciclos detectados en el grafo: {ciclo}\")\n",
    "            G.remove_edges_from([(n1, n2) for n1, n2 in G.edges() if (n1, n2) in ciclo])\n",
    "    except nx.NetworkXError as e:\n",
    "        print(f\"Error al eliminar ciclos: {e}\")\n",
    "    \n",
    "    # Encontrar nodos raÃ­z (sin predecesores)\n",
    "    posibles_raices = [n for n in G.nodes if G.in_degree(n) == 0]\n",
    "\n",
    "    if not posibles_raices:\n",
    "        print(\"No se encontrÃ³ un DataFrame raÃ­z. El grafo tiene ciclos o todos tienen predecesores.\")\n",
    "        return\n",
    "\n",
    "    # Si hay mÃ¡s de una raÃ­z, tratamos de crear Ã¡rboles por separado para cada una\n",
    "    arborescencias = {}\n",
    "    for root_df in posibles_raices:\n",
    "        try:\n",
    "            T = nx.bfs_tree(G, root_df)\n",
    "            arborescencias[root_df] = T\n",
    "        except nx.NetworkXError as e:\n",
    "            print(f\"Error al construir el Ã¡rbol desde {root_df}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Mostrar relaciones\n",
    "    for rel, cols in relaciones.items():\n",
    "        print(f\"{rel}: columnas comunes -> {cols}\")\n",
    "\n",
    "    # Dibujar todas las arborescencias encontradas\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    pos = nx.spring_layout(G, k=0.8)\n",
    "\n",
    "    # Dibujar cada Ã¡rbol raÃ­z\n",
    "    for root_df, T in arborescencias.items():\n",
    "        nx.draw(T, pos, with_labels=True, node_size=4000, node_color='lightblue',\n",
    "                font_size=10, font_weight='bold', edge_color='blue', arrows=True)\n",
    "    \n",
    "    plt.title(\"Arborescencia de Dependencias entre DataFrames\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc510d55-74ba-4294-83b9-e349b565a74e",
   "metadata": {},
   "source": [
    "### haversine\n",
    "ğŸ” Â¿QuÃ© hace?\n",
    "\n",
    "Calcula la distancia entre dos puntos en la superficie de la Tierra utilizando la fÃ³rmula de Haversine, que considera la curvatura del planeta (es decir, no asume una superficie plana como lo harÃ­a una distancia euclidiana).\n",
    "\n",
    "ParÃ¡metros:\n",
    "\n",
    "    ğŸ”¹lat1, lon1: Latitud y longitud del primer punto (en grados decimales).\n",
    "\n",
    "    ğŸ”¹lat2, lon2: Latitud y longitud del segundo punto (tambiÃ©n en grados decimales).\n",
    "\n",
    "ğŸ§  ExplicaciÃ³n paso a paso:\n",
    "\n",
    "    ğŸ”¹ Radio de la Tierra (R): Se toma como 6371 km (valor promedio).\n",
    "\n",
    "    ğŸ”¹ ConversiÃ³n a radianes: Las funciones trigonomÃ©tricas de math usan radianes, asÃ­ que se convierte cada latitud y longitud de grados a radianes.\n",
    "\n",
    "    ğŸ”¹ Diferencia angular: Calcula la diferencia entre latitudes y longitudes en radianes (dlat, dlon).\n",
    "\n",
    "ğŸ¼ FÃ³rmula de Haversine:\n",
    "\n",
    "    ğŸ”¹ Calcula el valor de a, que es una medida intermedia basada en el seno de las mitades de las diferencias angulares.\n",
    "\n",
    "    ğŸ”¹ Luego obtiene c, que es el Ã¡ngulo central entre los dos puntos en una esfera.\n",
    "\n",
    "    ğŸ”¹ Distancia final: Multiplica el radio de la Tierra por c para obtener la distancia en kilÃ³metros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51393513-3e34-4167-b020-b3d2021ddc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    # Radio de la Tierra en kilÃ³metros\n",
    "    R = 6371.0\n",
    "    \n",
    "    # Convertir de grados a radianes\n",
    "    lat1_rad = math.radians(lat1)\n",
    "    lon1_rad = math.radians(lon1)\n",
    "    lat2_rad = math.radians(lat2)\n",
    "    lon2_rad = math.radians(lon2)\n",
    "    \n",
    "    # Diferencias de latitudes y longitudes\n",
    "    dlat = lat2_rad - lat1_rad\n",
    "    dlon = lon2_rad - lon1_rad\n",
    "    \n",
    "    # FÃ³rmula de Haversine\n",
    "    a = math.sin(dlat / 2)**2 + math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(dlon / 2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    \n",
    "    # Distancia en kilÃ³metros\n",
    "    distance = R * c\n",
    "    return distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293253cf-70f2-4394-bee9-9b148209d370",
   "metadata": {},
   "source": [
    "### location_gps\n",
    "ğŸ” Â¿QuÃ© hace?\n",
    "\n",
    "Intenta determinar la ubicaciÃ³n del dispositivo basÃ¡ndose en la IP.\n",
    "\n",
    "ğŸ§  Â¿QuÃ© hace paso a paso?\n",
    "\n",
    "Llama a geocoder.ip('me'), que intenta determinar la ubicaciÃ³n del dispositivo basÃ¡ndose en la IP.\n",
    "\n",
    "Extrae las coordenadas de latitud y longitud (latlng) del resultado.\n",
    "\n",
    "Muestra las coordenadas por consola con print()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2b6f7d8-5b24-4be6-b39b-1eb4e8186457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def location_gps():\n",
    "    ubicacion = geocoder.ip('me')\n",
    "    \n",
    "    # Mostrar coordenadas\n",
    "    print(f\"Tu ubicaciÃ³n aproximada es: {ubicacion.latlng}\")\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
